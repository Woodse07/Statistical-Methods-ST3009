QUESTION 1:

Sample Space:
The set of all possible outcomes or results of an experiment.

Indicator Random Variable: 
Take value 1 if event E occurs and 0 if event E doesn't occur.

Probability Mass Function:  
A function that gives the probability that a discrete random variable is exactly equal to 
some value. 

Conditional Probability of an Event:
The probability that event E occurs *given* that event F has already occurred. P(E|F).
P(E|F) = P(E n F) / P(F)

Bayes Theorem:
P(E|F) = P(F|E)P(E) / P(F)
P(E).. chance of rain tomorrow, with no extra info.
P(F|E).. probability of a cloudy day before rain
P(E|F).. updated probability of rain tomorrow after observing clouds today
P(F).. chance of a cloudy day, with no extra info. 

Marginalization:
Refers to "summing out" the probability of a random variable X given the joint probability
distribution of X with other variables.
Roll two coins.. what is the probability the the first coin is heads?
Event E is first coint heads..
Event F1 is second coin heads..
Event F2 is second coin tails..
P(E) = P(E n F1) + P(E n F2) = (0.5*0.5) + (0.5*0.5) = 0.5 




QUESTION 2:

2 Bags
Bag A contains 3 white, 1 black
Bag B contains 1 white, 3 black
Toss a coin to choose A or B
Draw 5 balls, with replacement.
We observe 4 white balls and 1 black ball, what is probability we chose bag A..(Bayes Rule)
Sample space.. 4^4 = 256
P(E|F) = P(F|E)P(E) / P(F).
P(E|F).. probability we chose bag A given 4 white and 1 black. 
P(F|E).. probability we chose 4 white and 1 black given bag A.. (81/256=0.3164)
P(E).. probability of choosing bag A.. (0.5)
P(F).. probability of choosing 4 white and 1 black.. don't know this..

** NOTE: P(F) = P(F|E)P(E) + P(F|Ec)P(Ec) **
P(F|Ec).. probability of choosing 4 white and 1 black given bag B.. (3/256=0.0117)
P(Ec).. probability of choosing bag B.. (0.5)

P(E|F) = (0.3164*0.5) / ((0.3164*0.5) + (0.0117*0.5))
P(E|F) = 0.9643




Question 3:

Expected Value of a Random Variable:
E[X] = sumof{n}{i=1} xi P(X = xi) 
This is a weighted average of the possible values that X cant take, each value being weighted
according to the probability of that event occuring.

E[X+Y] = E[X] + E[Y].. proof in copy.

Two variables X and Y are independent if P(X = x and Y = y) = P(X = x)P(Y = y) for all x and
y.

E[XY] = E[X]E[Y].. proof in copy.

Covariance:
Say X and Y are random variables with expected values ux and uy. The covariance of X and Y is 
defined as Cov(X, Y) = E[X - ux)(Y - uy)]

Correlation:
The correlation between X and Y is defined as Corr(X, Y) = Cov(X, Y) / sqrt(Var(X)Var(Y))





